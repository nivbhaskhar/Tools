{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is TF-IDF ? \n",
    "\n",
    "You are given a collection of documents. Let N be the number of documents and _d_ be a particular document in the collection. Let _w_ be a word in the vocabulary list for the collection of documents.\n",
    "\n",
    "* Choices for __term-frequency__ *tf(w,d)*:\n",
    "  - _f(w,d)_ = number of times w appears in d (__sublinear_tf = False__, default setting in scikit-learn)\n",
    "  - log(1 + _f(w,d)_ ) (__sublinear_tf= True__)\n",
    "  \n",
    "\n",
    "Let __document-frequency__ *df(w)* = the number of documents in which _w_ occurs\n",
    "\n",
    "* Choices for __inverse-document-frequency__ *idf(w)*:\n",
    "  - log(N/df(w)) + 1 (__smooth_idf=False__)\n",
    "  - log(N+1/df(w)+1) + 1 (__smooth_idf= True__, default setting in scikit-learn) <br>\n",
    "    (Imagine adding an extra document to the collection which contains every word in the vocabulary list)\n",
    "    \n",
    "    \n",
    "* Then __tf-idf__ of _w_ in _d_ is given to be *tf-idf(w,d) = tf(w,d) x idf(w)* if *w* occurs in *d*\n",
    "* __tf-idf__ of _w_ in _d_ is 0 is *w* does not occur in *d*\n",
    "* The __tf-idf__ of _d_ is the vector of  __tf-idf__  of the words in the vocabulary list with respect to d\n",
    "* Sci-kit-learn normalizes the __tf-idf__ of every document _d_ so that it has unit 1 norm <br>\n",
    "  (__norm = 'l2'__ default setting in scikit-learn, __norm = 'l1'__, __norm=None__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal : Understand the scikit-learn syntax for finding TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the tf-idf representation of the simple list_of_documents given below using two methods\n",
    "\n",
    "* CountVectorizer + TfidfTranformer\n",
    "* TfidfVectorizer \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running example\n",
    "list_of_documents = [\"There are four words\", \n",
    "                     \"are there ? \" ,\n",
    "                     \"are there, are there ?\" ,\n",
    "                     \"four four four are there\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_count_vectorizer = CountVectorizer()\n",
    "count_sparse_array = my_count_vectorizer.fit_transform(list_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are', 'four', 'there', 'words']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = my_count_vectorizer.get_feature_names()\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(my_count_vectorizer.vocabulary_.get('there'))\n",
    "print(my_count_vectorizer.vocabulary_.get('fifth_word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 2)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 2)\t2\n",
      "  (2, 0)\t2\n",
      "  (3, 2)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4x4 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(count_sparse_array))\n",
    "print(count_sparse_array)\n",
    "count_sparse_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1],\n",
       "       [1, 0, 1, 0],\n",
       "       [2, 0, 2, 0],\n",
       "       [1, 3, 1, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_array = count_sparse_array.toarray()\n",
    "count_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf Tranformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transformer = TfidfTransformer(sublinear_tf = False, smooth_idf=False, norm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_from_sparse_count_array = my_transformer.fit_transform(count_sparse_array)\n",
    "tfidf_from_count_array = my_transformer.fit_transform(count_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Number of unequal entries in these two tfidfs is 0\n"
     ]
    }
   ],
   "source": [
    "print(type(tfidf_from_sparse_count_array), type(tfidf_from_sparse_count_array))\n",
    "#Checking equality of these two tfidfs\n",
    "print(f\"Number of unequal entries in these two tfidfs is {(tfidf_from_sparse_count_array != tfidf_from_count_array).nnz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (4,)\n",
      "[1.         1.69314718 1.         2.38629436]\n"
     ]
    }
   ],
   "source": [
    "idf = my_transformer.idf_\n",
    "print(type(idf), idf.shape)\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1],\n",
       "       [1, 0, 1, 0],\n",
       "       [2, 0, 2, 0],\n",
       "       [1, 3, 1, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.69314718, 1.        , 2.38629436],\n",
       "       [1.        , 0.        , 1.        , 0.        ],\n",
       "       [2.        , 0.        , 2.        , 0.        ],\n",
       "       [1.        , 5.07944154, 1.        , 0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_from_count_array.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It basically is like combining CountVectorizer and TfidfTranformer into one step. You can customize it using the same parameters as above. You can also use the idf, get_feature_names() to extract the idf of words and the vocabular list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vectorizer = TfidfVectorizer(sublinear_tf = False, smooth_idf=False, norm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_tfidf = my_vectorizer.fit_transform(list_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 3)\t2.386294361119891\n",
      "  (0, 1)\t1.6931471805599454\n",
      "  (0, 0)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (2, 0)\t2.0\n",
      "  (2, 2)\t2.0\n",
      "  (3, 1)\t5.079441541679836\n",
      "  (3, 0)\t1.0\n",
      "  (3, 2)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(type(second_tfidf))\n",
    "print(second_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are', 'four', 'there', 'words']\n",
      "<class 'numpy.ndarray'> (4,)\n",
      "[1.         1.69314718 1.         2.38629436]\n"
     ]
    }
   ],
   "source": [
    "second_vocabulary = my_vectorizer.get_feature_names()\n",
    "print(second_vocabulary)\n",
    "second_idf = my_vectorizer.idf_\n",
    "print(type(second_idf), second_idf.shape)\n",
    "print(second_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.69314718, 1.        , 2.38629436],\n",
       "       [1.        , 0.        , 1.        , 0.        ],\n",
       "       [2.        , 0.        , 2.        , 0.        ],\n",
       "       [1.        , 5.07944154, 1.        , 0.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

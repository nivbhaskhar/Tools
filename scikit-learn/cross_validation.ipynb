{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we predicted precipitation from other weather features using a [Decision Tree regressor](https://github.com/nivbhaskhar/Tools/blob/master/scikit-learn/decision_tree_regressor.md). There, we split up the input data into training and test data sets. This meant that the test data set was never used in training at all. In this notebook, we'll use cross validation to more efficiently use the input data for both training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The basic idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to split up your dataset into k chunks or *folds*. Let's call the folds F_1, F_2, ...F_k. We'll proceed to train k Models (M_1,....M_k) on different training and test-data as follows:\n",
    "\n",
    "* Train the i-th model M_i on training data comprising of all folds except the i-th fold F_i. \n",
    "* Evaluate Model_i on test data = F_i\n",
    "\n",
    "Thus, for each of the k models M_i, we get a validation error estimate E_i.\n",
    "\n",
    "We report the k validation error estimates as *cross-validation scores* \n",
    "\n",
    "\n",
    "* The average of these error-scores tells us how biased our model is. If the average error is low, this implies our model has low bias.\n",
    "\n",
    "\n",
    "* The standard deviation of these error-scores tells us how our model's performance varies with the training dataset used. If the standard deviation is high, this means our model has high variance \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather data from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['date','avgtemp', 'mintemp', 'pp', 'snow', 'wind-dir', 'wind-speed', 'wind-gut', 'air-pressure', 'sunshine', 'dummy']\n",
    "#Reads the comma separated csv into a pandas dataframe\n",
    "daily_weather_df =pd.read_csv('KCQT0.csv', sep=',',names=col_names, header = None)\n",
    "#Delete irrelevant cols\n",
    "del daily_weather_df['dummy']\n",
    "del daily_weather_df['air-pressure']\n",
    "del daily_weather_df['wind-speed']\n",
    "del daily_weather_df['snow']\n",
    "del daily_weather_df['wind-dir']\n",
    "del daily_weather_df['date']\n",
    "del daily_weather_df['mintemp']\n",
    "#Delete rows with NaN entries\n",
    "daily_weather_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avgtemp</th>\n",
       "      <th>pp</th>\n",
       "      <th>wind-gut</th>\n",
       "      <th>sunshine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.4</td>\n",
       "      <td>13.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1018.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.4</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1026.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1024.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.3</td>\n",
       "      <td>21.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1018.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avgtemp    pp  wind-gut  sunshine\n",
       "0     10.4  13.9       2.0    1018.9\n",
       "1     12.0  15.6       8.1    1021.0\n",
       "2     11.4  18.9       1.3    1026.5\n",
       "3     12.6  20.0       3.0    1024.9\n",
       "4     13.3  21.7       1.9    1018.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop precipitation column to get weather_features\n",
    "weather_features = daily_weather_df.drop(['pp'], axis=1)\n",
    "precipitation_labels = daily_weather_df['pp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor(max_depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for computing cross validation scores over k folds is \n",
    "\n",
    "\n",
    "```cross_val_score(model, features, labels, scoring=scoring_method, cv=k)```\n",
    "\n",
    "\n",
    "One thing to note is that the scoring expects a scoring_method/function for which *greater is better* (i.e. it wants to maximize the score). So you should not give it a loss function (for which lesser is better).\n",
    "\n",
    "\n",
    "We used mean_squared_error as a loss function when we evaluated our Decision Tree regressor one just one training-test split. Here, we'll use *neg_mean_squared_error*, which is just the negative of the mean_squared_error.\n",
    "\n",
    "\n",
    "Minimizing mean_squared_error is maximizing neg_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(tree_reg, weather_features, precipitation_labels,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[-4.21900535 -3.27126449 -3.13457551 -3.14451502 -3.38513429]\n"
     ]
    }
   ],
   "source": [
    "print(type(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.430898932367799"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40460168118423967"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to earlier validation-error estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error on our test-data set from earlier was 3.13. (We reported the root-mean square error to be around 1.77). We see that the average cross validation score is -3.43, or the average mean-square error of test-datasets across the k=5 folds is 3.43."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validation error gives a much better estimate of the error, as it uses every element in the dataset as a test-input (exactly once in some fold). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
